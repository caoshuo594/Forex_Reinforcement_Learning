{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8359d23c",
   "metadata": {},
   "source": [
    "# 🤖 外汇强化学习交易系统完整教程\n",
    "\n",
    "## 📚 课程概述\n",
    "\n",
    "本教程将带您完成从零到部署的完整流程：\n",
    "\n",
    "1. 📊 **数据获取** - 从MT5获取历史数据\n",
    "2. 🏗️ **环境构建** - 创建交易环境\n",
    "3. 🎓 **模型训练** - 使用PPO算法训练\n",
    "4. 📈 **结果分析** - 可视化训练效果\n",
    "5. 📦 **ONNX导出** - 导出为MT5可用格式\n",
    "6. 🚀 **部署上线** - 部署到MT5平台\n",
    "\n",
    "---\n",
    "\n",
    "**作者**: AI Trading System  \n",
    "**日期**: 2025-10-31  \n",
    "**版本**: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5496d889",
   "metadata": {},
   "source": [
    "## 📦 第一步：环境准备\n",
    "\n",
    "首先安装必要的依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48632294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装必要的包（如果尚未安装）\n",
    "# !pip install gymnasium stable-baselines3 torch numpy pandas onnx onnxruntime tensorboard matplotlib scikit-learn MetaTrader5\n",
    "\n",
    "# 导入所有必要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import torch\n",
    "import torch.onnx\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 配置matplotlib中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"✅ 所有库导入成功！\")\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1fa51",
   "metadata": {},
   "source": [
    "## 📊 第二步：数据获取与处理\n",
    "\n",
    "### 2.1 从MT5获取历史数据\n",
    "\n",
    "这里我们从MT5获取EURUSD的历史数据，并计算所需的技术指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt5\n",
    "\n",
    "def initialize_mt5():\n",
    "    \"\"\"初始化MT5连接\"\"\"\n",
    "    if not mt5.initialize():\n",
    "        print(\"❌ MT5初始化失败\")\n",
    "        return False\n",
    "    print(f\"✅ MT5版本: {mt5.version()}\")\n",
    "    return True\n",
    "\n",
    "def get_historical_data(symbol=\"EURUSD\", timeframe=mt5.TIMEFRAME_H1, bars=50000):\n",
    "    \"\"\"获取历史数据\"\"\"\n",
    "    print(f\"📥 获取 {symbol} {timeframe} 数据, {bars} 根K线...\")\n",
    "    \n",
    "    rates = mt5.copy_rates_from_pos(symbol, timeframe, 0, bars)\n",
    "    \n",
    "    if rates is None:\n",
    "        print(f\"❌ 获取数据失败: {mt5.last_error()}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(rates)\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    \n",
    "    print(f\"✅ 获取成功: {len(df)} 根K线\")\n",
    "    print(f\"📅 时间范围: {df['time'].min()} 到 {df['time'].max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 尝试连接MT5并获取数据\n",
    "if initialize_mt5():\n",
    "    # 获取多个时间周期的数据\n",
    "    df_h1 = get_historical_data(\"EURUSD\", mt5.TIMEFRAME_H1, 50000)\n",
    "    df_h4 = get_historical_data(\"EURUSD\", mt5.TIMEFRAME_H4, 20000)\n",
    "    df_m15 = get_historical_data(\"EURUSD\", mt5.TIMEFRAME_M15, 50000)\n",
    "    \n",
    "    mt5.shutdown()\n",
    "    print(\"\\n✅ 数据获取完成，MT5已关闭\")\n",
    "else:\n",
    "    print(\"\\n⚠️ 无法连接MT5，将使用已有数据文件\")\n",
    "    # 如果无法连接MT5，加载已保存的数据\n",
    "    if Path('EURUSD_processed.csv').exists():\n",
    "        df_m15 = pd.read_csv('EURUSD_processed.csv')\n",
    "        print(f\"✅ 从文件加载数据: {len(df_m15)} 行\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b5e98",
   "metadata": {},
   "source": [
    "### 2.2 计算技术指标\n",
    "\n",
    "计算RSI、ATR、MACD等技术指标用于训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d97d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rsi(data, period=14):\n",
    "    \"\"\"计算RSI指标\"\"\"\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi / 100.0  # 归一化到0-1\n",
    "\n",
    "def calculate_atr_norm(data, period=14, lookback=100):\n",
    "    \"\"\"计算ATR标准化值\"\"\"\n",
    "    high = data['high']\n",
    "    low = data['low']\n",
    "    close = data['close']\n",
    "    \n",
    "    tr1 = high - low\n",
    "    tr2 = abs(high - close.shift())\n",
    "    tr3 = abs(low - close.shift())\n",
    "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    atr = tr.rolling(window=period).mean()\n",
    "    \n",
    "    atr_mean = atr.rolling(window=lookback).mean()\n",
    "    atr_std = atr.rolling(window=lookback).std()\n",
    "    atr_norm = (atr - atr_mean) / (atr_std + 1e-8)\n",
    "    \n",
    "    return atr_norm\n",
    "\n",
    "def calculate_macd_hist_norm(data, lookback=100):\n",
    "    \"\"\"计算MACD柱状图标准化值\"\"\"\n",
    "    exp1 = data['close'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = data['close'].ewm(span=26, adjust=False).mean()\n",
    "    macd = exp1 - exp2\n",
    "    signal = macd.ewm(span=9, adjust=False).mean()\n",
    "    hist = macd - signal\n",
    "    \n",
    "    hist_mean = hist.rolling(window=lookback).mean()\n",
    "    hist_std = hist.rolling(window=lookback).std()\n",
    "    hist_norm = (hist - hist_mean) / (hist_std + 1e-8)\n",
    "    \n",
    "    return hist_norm\n",
    "\n",
    "def calculate_trend_indicator(data, lookback=50):\n",
    "    \"\"\"计算趋势指标\"\"\"\n",
    "    sma = data['close'].rolling(window=lookback).mean()\n",
    "    trend = (data['close'] - sma) / sma\n",
    "    return trend * 100  # 转换为百分比\n",
    "\n",
    "# 为M15数据计算所有指标\n",
    "print(\"🔧 计算技术指标...\")\n",
    "\n",
    "if 'df_m15' in locals() and df_m15 is not None:\n",
    "    df_m15['M15_RSI'] = calculate_rsi(df_m15['close'], 14)\n",
    "    df_m15['M15_ATR_norm'] = calculate_atr_norm(df_m15, 14, 100)\n",
    "    df_m15['M15_MACD_hist_norm'] = calculate_macd_hist_norm(df_m15, 100)\n",
    "    \n",
    "    # 对于H1和H4数据，需要重采样到M15\n",
    "    if 'df_h1' in locals() and df_h1 is not None:\n",
    "        df_h1['H1_RSI'] = calculate_rsi(df_h1['close'], 14)\n",
    "        df_h1['H1_Trend'] = calculate_trend_indicator(df_h1, 50)\n",
    "    \n",
    "    if 'df_h4' in locals() and df_h4 is not None:\n",
    "        df_h4['H4_RSI'] = calculate_rsi(df_h4['close'], 14)\n",
    "        df_h4['H4_Trend'] = calculate_trend_indicator(df_h4, 50)\n",
    "    \n",
    "    # 删除NaN值\n",
    "    df_clean = df_m15.dropna()\n",
    "    \n",
    "    print(f\"✅ 技术指标计算完成\")\n",
    "    print(f\"📊 清洗后数据: {len(df_clean)} 行\")\n",
    "    print(f\"\\n数据预览:\")\n",
    "    print(df_clean[['close', 'M15_RSI', 'M15_ATR_norm', 'M15_MACD_hist_norm']].head())\n",
    "    \n",
    "    # 保存处理后的数据\n",
    "    df_clean.to_csv('EURUSD_processed.csv', index=False)\n",
    "    print(\"\\n💾 数据已保存到 EURUSD_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd98566",
   "metadata": {},
   "source": [
    "## 🏗️ 第三步：构建交易环境\n",
    "\n",
    "创建符合Gymnasium标准的交易环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf076e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForexTradingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    外汇交易强化学习环境\n",
    "    \n",
    "    状态空间: 10维向量 (7个市场指标 + 3个持仓状态)\n",
    "    动作空间: 4个离散动作 (Hold, Open Long, Open Short, Close)\n",
    "    \"\"\"\n",
    "    \n",
    "    metadata = {'render_modes': ['human']}\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        initial_balance: float = 10000.0,\n",
    "        leverage: int = 20,\n",
    "        trade_size_lots: float = 0.1,\n",
    "        spread_cost_pips: float = 2.0,\n",
    "        max_position_hold_steps: int = 480,\n",
    "        max_drawdown_pct: float = 0.50\n",
    "    ):\n",
    "        super(ForexTradingEnv, self).__init__()\n",
    "        \n",
    "        # 账户参数\n",
    "        self.initial_balance = initial_balance\n",
    "        self.leverage = leverage\n",
    "        self.lot_size_standard = 100000\n",
    "        self.trade_size_lots = trade_size_lots\n",
    "        \n",
    "        # 交易成本\n",
    "        self.spread_cost_pips = spread_cost_pips\n",
    "        self.pip_value = 10 * trade_size_lots\n",
    "        \n",
    "        # 风险控制\n",
    "        self.max_position_hold_steps = max_position_hold_steps\n",
    "        self.max_drawdown_pct = max_drawdown_pct\n",
    "        \n",
    "        # 数据处理\n",
    "        self.df = df.copy()\n",
    "        self.max_steps = len(df) - 1\n",
    "        self.warmup_steps = 100\n",
    "        \n",
    "        # 验证数据完整性\n",
    "        required_columns = [\n",
    "            'close', 'M15_RSI', 'M15_ATR_norm', 'M15_MACD_hist_norm',\n",
    "            'H1_RSI', 'H1_Trend_Indicator', 'H4_RSI', 'H4_Trend_Indicator'\n",
    "        ]\n",
    "        missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"DataFrame缺少必需列: {missing_cols}\")\n",
    "        \n",
    "        # 定义状态空间 (10维)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0, -10, -10, 0, -10, 0, -10, 0, -20, 0], dtype=np.float32),\n",
    "            high=np.array([1, 10, 10, 1, 10, 1, 10, 2, 20, 1], dtype=np.float32),\n",
    "            shape=(10,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # 定义动作空间 (4个离散动作)\n",
    "        # 0: Hold, 1: Open Long, 2: Open Short, 3: Close\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        # 初始化状态变量\n",
    "        self._reset_state()\n",
    "        \n",
    "        print(f\"✅ ForexTradingEnv初始化成功\")\n",
    "        print(f\"   数据长度: {len(df)}\")\n",
    "        print(f\"   初始余额: ${initial_balance}\")\n",
    "        print(f\"   状态空间: {self.observation_space.shape}\")\n",
    "        print(f\"   动作空间: {self.action_space.n}\")\n",
    "    \n",
    "    def _reset_state(self):\n",
    "        \"\"\"重置环境状态\"\"\"\n",
    "        self.balance = self.initial_balance\n",
    "        self.equity = self.initial_balance\n",
    "        self.peak_balance = self.initial_balance\n",
    "        \n",
    "        self.position_state = 0\n",
    "        self.entry_price = 0.0\n",
    "        self.position_pnl = 0.0\n",
    "        self.steps_since_trade = 0\n",
    "        \n",
    "        self.current_step = self.warmup_steps\n",
    "        self.total_trades = 0\n",
    "        self.winning_trades = 0\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        \"\"\"获取当前状态观测\"\"\"\n",
    "        row = self.df.iloc[self.current_step]\n",
    "        \n",
    "        obs = np.array([\n",
    "            row['M15_RSI'],\n",
    "            row['M15_ATR_norm'],\n",
    "            row['M15_MACD_hist_norm'],\n",
    "            row['H1_RSI'],\n",
    "            row['H1_Trend_Indicator'],\n",
    "            row['H4_RSI'],\n",
    "            row['H4_Trend_Indicator'],\n",
    "            float(self.position_state),\n",
    "            self.position_pnl / 100.0,\n",
    "            min(self.steps_since_trade / self.max_position_hold_steps, 1.0)\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        return np.clip(obs, self.observation_space.low, self.observation_space.high)\n",
    "    \n",
    "    def _get_info(self):\n",
    "        \"\"\"获取额外信息\"\"\"\n",
    "        return {\n",
    "            'balance': self.balance,\n",
    "            'equity': self.equity,\n",
    "            'position': self.position_state,\n",
    "            'total_trades': self.total_trades,\n",
    "            'winning_trades': self.winning_trades,\n",
    "            'profit_pct': (self.balance - self.initial_balance) / self.initial_balance * 100\n",
    "        }\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self._reset_state()\n",
    "        return self._get_observation(), self._get_info()\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"执行一步交易动作\"\"\"\n",
    "        current_price = self.df.iloc[self.current_step]['close']\n",
    "        reward = 0.0\n",
    "        \n",
    "        # 执行动作并计算奖励\n",
    "        if action == 1 and self.position_state == 0:  # 开多单\n",
    "            self.position_state = 1\n",
    "            self.entry_price = current_price\n",
    "            self.steps_since_trade = 0\n",
    "            reward = -0.1  # 开仓成本\n",
    "            self.total_trades += 1\n",
    "            \n",
    "        elif action == 2 and self.position_state == 0:  # 开空单\n",
    "            self.position_state = 2\n",
    "            self.entry_price = current_price\n",
    "            self.steps_since_trade = 0\n",
    "            reward = -0.1\n",
    "            self.total_trades += 1\n",
    "            \n",
    "        elif action == 3 and self.position_state != 0:  # 平仓\n",
    "            if self.position_state == 1:\n",
    "                pips = (current_price - self.entry_price) * 10000\n",
    "            else:\n",
    "                pips = (self.entry_price - current_price) * 10000\n",
    "            \n",
    "            realized_pnl = pips * self.pip_value - self.spread_cost_pips * self.pip_value\n",
    "            self.balance += realized_pnl\n",
    "            reward = realized_pnl / 10.0  # 缩放奖励\n",
    "            \n",
    "            if realized_pnl > 0:\n",
    "                self.winning_trades += 1\n",
    "            \n",
    "            self.position_state = 0\n",
    "            self.entry_price = 0.0\n",
    "            self.position_pnl = 0.0\n",
    "        \n",
    "        # 更新持仓盈亏\n",
    "        if self.position_state != 0:\n",
    "            if self.position_state == 1:\n",
    "                pips = (current_price - self.entry_price) * 10000\n",
    "            else:\n",
    "                pips = (self.entry_price - current_price) * 10000\n",
    "            self.position_pnl = pips * self.pip_value\n",
    "            self.steps_since_trade += 1\n",
    "        \n",
    "        # 更新权益\n",
    "        self.equity = self.balance + self.position_pnl\n",
    "        self.peak_balance = max(self.peak_balance, self.equity)\n",
    "        \n",
    "        # 检查终止条件\n",
    "        self.current_step += 1\n",
    "        terminated = False\n",
    "        truncated = self.current_step >= self.max_steps\n",
    "        \n",
    "        # 检查最大回撤\n",
    "        drawdown = (self.peak_balance - self.equity) / self.peak_balance\n",
    "        if drawdown > self.max_drawdown_pct:\n",
    "            terminated = True\n",
    "            reward = -100\n",
    "        \n",
    "        return self._get_observation(), reward, terminated, truncated, self._get_info()\n",
    "\n",
    "print(\"✅ ForexTradingEnv 类定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93a459",
   "metadata": {},
   "source": [
    "## 🎓 第四步：模型训练\n",
    "\n",
    "使用PPO算法训练交易策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcaa60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练配置\n",
    "TOTAL_TIMESTEPS = 500000  # 总训练步数\n",
    "EVAL_FREQ = 10000\n",
    "SAVE_FREQ = 50000\n",
    "N_EVAL_EPISODES = 5\n",
    "\n",
    "# 环境参数\n",
    "INITIAL_BALANCE = 10000.0\n",
    "TRADE_SIZE_LOTS = 0.1\n",
    "\n",
    "# PPO超参数\n",
    "LEARNING_RATE = 3e-4\n",
    "N_STEPS = 2048\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 10\n",
    "\n",
    "print(\"🎯 训练配置:\")\n",
    "print(f\"   总训练步数: {TOTAL_TIMESTEPS:,}\")\n",
    "print(f\"   学习率: {LEARNING_RATE}\")\n",
    "print(f\"   批大小: {BATCH_SIZE}\")\n",
    "print(f\"   初始余额: ${INITIAL_BALANCE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba346803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "df = pd.read_csv('EURUSD_processed.csv')\n",
    "print(f\"📊 加载数据: {len(df)} 行\")\n",
    "\n",
    "# 分割训练集和测试集\n",
    "split_idx = int(len(df) * 0.8)\n",
    "train_df = df.iloc[:split_idx].reset_index(drop=True)\n",
    "test_df = df.iloc[split_idx:].reset_index(drop=True)\n",
    "\n",
    "print(f\"训练集: {len(train_df)} 行\")\n",
    "print(f\"测试集: {len(test_df)} 行\")\n",
    "\n",
    "# 创建目录\n",
    "Path('./logs').mkdir(exist_ok=True)\n",
    "Path('./models').mkdir(exist_ok=True)\n",
    "Path('./models/checkpoints').mkdir(exist_ok=True)\n",
    "Path('./models/best_model').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练和评估环境\n",
    "print(\"\\n🏗️ 创建环境...\")\n",
    "\n",
    "train_env = ForexTradingEnv(train_df, initial_balance=INITIAL_BALANCE, trade_size_lots=TRADE_SIZE_LOTS)\n",
    "train_env = Monitor(train_env, './logs/train_monitor.csv')\n",
    "train_env = DummyVecEnv([lambda: train_env])\n",
    "\n",
    "eval_env = ForexTradingEnv(test_df, initial_balance=INITIAL_BALANCE, trade_size_lots=TRADE_SIZE_LOTS)\n",
    "eval_env = Monitor(eval_env, './logs/eval_monitor.csv')\n",
    "eval_env = DummyVecEnv([lambda: eval_env])\n",
    "\n",
    "print(\"✅ 环境创建完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4317832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建PPO模型\n",
    "print(\"\\n🤖 创建PPO模型...\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=train_env,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    n_steps=N_STEPS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.01,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    policy_kwargs=dict(\n",
    "        net_arch=dict(pi=[256, 256], vf=[256, 256])\n",
    "    ),\n",
    "    tensorboard_log='./logs',\n",
    "    device=device,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"✅ 模型创建完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a8b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置回调\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path='./models/best_model',\n",
    "    log_path='./logs',\n",
    "    eval_freq=EVAL_FREQ,\n",
    "    n_eval_episodes=N_EVAL_EPISODES,\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=SAVE_FREQ,\n",
    "    save_path='./models/checkpoints',\n",
    "    name_prefix='ppo_forex',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"✅ 回调配置完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093523ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🚀 开始训练...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "try:\n",
    "    model.learn(\n",
    "        total_timesteps=TOTAL_TIMESTEPS,\n",
    "        callback=[eval_callback, checkpoint_callback],\n",
    "        progress_bar=True\n",
    "    )\n",
    "    \n",
    "    # 保存最终模型\n",
    "    model.save('./models/ppo_forex_final')\n",
    "    print(\"\\n✅ 训练完成！模型已保存\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n⚠️ 训练被中断\")\n",
    "    model.save('./models/ppo_forex_interrupted')\n",
    "    print(\"模型已保存\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"\\n⏱️ 训练时长: {duration}\")\n",
    "\n",
    "# 清理\n",
    "train_env.close()\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d5136",
   "metadata": {},
   "source": [
    "## 📈 第五步：训练结果分析\n",
    "\n",
    "可视化训练过程和效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bef25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练日志\n",
    "train_log = pd.read_csv('./logs/train_monitor.csv', skiprows=1)\n",
    "eval_log = pd.read_csv('./logs/eval_monitor.csv', skiprows=1)\n",
    "\n",
    "print(\"📊 训练统计:\")\n",
    "print(f\"   训练回合数: {len(train_log)}\")\n",
    "print(f\"   平均奖励: {train_log['r'].mean():.2f}\")\n",
    "print(f\"   最佳奖励: {train_log['r'].max():.2f}\")\n",
    "print(f\"\\n📊 测试统计:\")\n",
    "print(f\"   测试回合数: {len(eval_log)}\")\n",
    "print(f\"   平均奖励: {eval_log['r'].mean():.2f}\")\n",
    "print(f\"   最佳奖励: {eval_log['r'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建可视化\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 训练奖励曲线\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(train_log['r'], alpha=0.3, label='原始')\n",
    "ax1.plot(train_log['r'].rolling(5).mean(), linewidth=2, label='移动平均')\n",
    "ax1.axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "ax1.set_xlabel('回合')\n",
    "ax1.set_ylabel('奖励')\n",
    "ax1.set_title('训练集奖励曲线')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 评估奖励曲线\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(eval_log['r'], alpha=0.3, label='原始')\n",
    "ax2.plot(eval_log['r'].rolling(5).mean(), linewidth=2, label='移动平均')\n",
    "ax2.axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('回合')\n",
    "ax2.set_ylabel('奖励')\n",
    "ax2.set_title('测试集奖励曲线')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 奖励分布\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(train_log['r'], bins=30, alpha=0.5, label='训练集', density=True)\n",
    "ax3.hist(eval_log['r'], bins=30, alpha=0.5, label='测试集', density=True)\n",
    "ax3.axvline(x=0, color='r', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('奖励')\n",
    "ax3.set_ylabel('频率')\n",
    "ax3.set_title('奖励分布对比')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 评估进展\n",
    "ax4 = axes[1, 1]\n",
    "if Path('./logs/evaluations.npz').exists():\n",
    "    evals = np.load('./logs/evaluations.npz')\n",
    "    if 'results' in evals:\n",
    "        results = evals['results']\n",
    "        timesteps = evals['timesteps']\n",
    "        means = [np.mean(r) for r in results]\n",
    "        stds = [np.std(r) for r in results]\n",
    "        \n",
    "        ax4.errorbar(timesteps, means, yerr=stds, marker='o', capsize=5)\n",
    "        ax4.axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "        ax4.set_xlabel('训练步数')\n",
    "        ax4.set_ylabel('平均奖励')\n",
    "        ax4.set_title('评估性能进展')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        best_idx = np.argmax(means)\n",
    "        print(f\"\\n🏆 最佳模型: 第 {timesteps[best_idx]} 步, 平均奖励: {means[best_idx]:.2f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./logs/training_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ 分析图表已保存: ./logs/training_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d0315",
   "metadata": {},
   "source": [
    "## 📦 第六步：导出ONNX模型\n",
    "\n",
    "将训练好的模型导出为MT5可用的ONNX格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyWrapper(torch.nn.Module):\n",
    "    \"\"\"包装PPO策略网络\"\"\"\n",
    "    def __init__(self, policy_net):\n",
    "        super(PolicyWrapper, self).__init__()\n",
    "        self.policy_net = policy_net\n",
    "    \n",
    "    def forward(self, obs):\n",
    "        features = self.policy_net.extract_features(obs)\n",
    "        latent_pi = self.policy_net.mlp_extractor.forward_actor(features)\n",
    "        action_logits = self.policy_net.action_net(latent_pi)\n",
    "        action_probs = torch.softmax(action_logits, dim=-1)\n",
    "        return action_probs\n",
    "\n",
    "print(\"✅ PolicyWrapper 定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出ONNX模型\n",
    "print(\"\\n📦 导出ONNX模型...\")\n",
    "\n",
    "model_path = './models/best_model/best_model.zip'\n",
    "onnx_path = './models/forex_policy.onnx'\n",
    "\n",
    "# 加载最佳模型\n",
    "model = PPO.load(model_path, device='cpu')\n",
    "policy = model.policy\n",
    "policy.eval()\n",
    "policy.to('cpu')\n",
    "\n",
    "# 包装策略\n",
    "wrapped_policy = PolicyWrapper(policy)\n",
    "wrapped_policy.eval()\n",
    "\n",
    "# 创建dummy输入\n",
    "dummy_input = torch.randn(1, 10, dtype=torch.float32)\n",
    "\n",
    "print(f\"输入形状: {dummy_input.shape}\")\n",
    "\n",
    "# 导出ONNX\n",
    "torch.onnx.export(\n",
    "    wrapped_policy,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    input_names=['observation'],\n",
    "    output_names=['action_probs'],\n",
    "    dynamic_axes={},\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    export_params=True\n",
    ")\n",
    "\n",
    "print(f\"✅ ONNX模型已导出: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证ONNX模型\n",
    "print(\"\\n🔍 验证ONNX模型...\")\n",
    "\n",
    "# 检查模型\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"✅ 模型结构有效\")\n",
    "\n",
    "# 测试推理\n",
    "ort_session = ort.InferenceSession(onnx_path)\n",
    "test_input = np.random.randn(1, 10).astype(np.float32)\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: test_input}\n",
    "ort_outputs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "print(f\"✅ 测试推理成功\")\n",
    "print(f\"   输入形状: {test_input.shape}\")\n",
    "print(f\"   输出形状: {ort_outputs[0].shape}\")\n",
    "print(f\"   输出示例: {ort_outputs[0][0]}\")\n",
    "print(f\"   概率和: {ort_outputs[0][0].sum():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4184d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成模型规格文档\n",
    "spec = {\n",
    "    'model_file': 'forex_policy.onnx',\n",
    "    'input_name': 'observation',\n",
    "    'input_shape': [1, 10],\n",
    "    'input_type': 'float32',\n",
    "    'output_name': 'action_probs',\n",
    "    'output_shape': [1, 4],\n",
    "    'output_type': 'float32',\n",
    "    'actions': {\n",
    "        '0': 'Hold',\n",
    "        '1': 'Open Long',\n",
    "        '2': 'Open Short',\n",
    "        '3': 'Close'\n",
    "    },\n",
    "    'opset_version': 11,\n",
    "    'created_at': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open('./models/forex_policy_spec.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(spec, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n✅ 模型规格已保存: ./models/forex_policy_spec.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd64e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成测试用例\n",
    "print(\"\\n🧪 生成测试用例...\")\n",
    "\n",
    "test_cases = []\n",
    "for i in range(10):\n",
    "    test_input = np.random.randn(1, 10).astype(np.float32)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: test_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)\n",
    "    \n",
    "    test_cases.append({\n",
    "        'case_id': i + 1,\n",
    "        'input': test_input.tolist(),\n",
    "        'expected_output': ort_outputs[0].tolist(),\n",
    "        'expected_action': int(np.argmax(ort_outputs[0]))\n",
    "    })\n",
    "\n",
    "with open('./models/forex_policy_test_cases.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_cases, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ 已生成 {len(test_cases)} 个测试用例\")\n",
    "print(\"   保存位置: ./models/forex_policy_test_cases.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22333722",
   "metadata": {},
   "source": [
    "## 🚀 第七步：部署到MT5\n",
    "\n",
    "将ONNX模型部署到MetaTrader 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57561a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# 自动部署到MT5\n",
    "mt5_files_path = os.path.join(\n",
    "    os.environ['APPDATA'],\n",
    "    'MetaQuotes',\n",
    "    'Terminal',\n",
    "    'BB16F565FAAA6B23A20C26C49416FF05',\n",
    "    'MQL5',\n",
    "    'Files'\n",
    ")\n",
    "\n",
    "if os.path.exists(mt5_files_path):\n",
    "    # 复制ONNX模型\n",
    "    shutil.copy2(onnx_path, mt5_files_path)\n",
    "    print(f\"✅ 模型已复制到: {mt5_files_path}\")\n",
    "    print(f\"   文件: forex_policy.onnx\")\n",
    "    \n",
    "    # 检查文件\n",
    "    deployed_file = os.path.join(mt5_files_path, 'forex_policy.onnx')\n",
    "    if os.path.exists(deployed_file):\n",
    "        size = os.path.getsize(deployed_file) / 1024\n",
    "        print(f\"   大小: {size:.2f} KB\")\n",
    "else:\n",
    "    print(f\"⚠️ MT5目录不存在: {mt5_files_path}\")\n",
    "    print(\"   请手动复制 forex_policy.onnx 到 MT5/Files/ 目录\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e803aca8",
   "metadata": {},
   "source": [
    "## 📋 部署总结\n",
    "\n",
    "### ✅ 完成的工作\n",
    "\n",
    "1. **数据准备** ✅\n",
    "   - 从MT5获取历史数据\n",
    "   - 计算技术指标\n",
    "   - 数据清洗和保存\n",
    "\n",
    "2. **环境构建** ✅\n",
    "   - 创建Gymnasium交易环境\n",
    "   - 定义状态空间和动作空间\n",
    "   - 实现奖励函数\n",
    "\n",
    "3. **模型训练** ✅\n",
    "   - 使用PPO算法训练\n",
    "   - 保存最佳模型\n",
    "   - 训练过程监控\n",
    "\n",
    "4. **结果分析** ✅\n",
    "   - 可视化训练曲线\n",
    "   - 分析模型性能\n",
    "   - 保存分析图表\n",
    "\n",
    "5. **ONNX导出** ✅\n",
    "   - 导出ONNX模型\n",
    "   - 验证模型有效性\n",
    "   - 生成测试用例\n",
    "\n",
    "6. **模型部署** ✅\n",
    "   - 复制到MT5目录\n",
    "   - 生成部署文档\n",
    "\n",
    "### 📁 生成的文件\n",
    "\n",
    "- `EURUSD_processed.csv` - 处理后的数据\n",
    "- `models/best_model/best_model.zip` - 最佳模型\n",
    "- `models/forex_policy.onnx` - ONNX模型\n",
    "- `models/forex_policy_spec.json` - 模型规格\n",
    "- `models/forex_policy_test_cases.json` - 测试用例\n",
    "- `logs/training_analysis.png` - 训练分析图\n",
    "\n",
    "### 🎯 下一步操作\n",
    "\n",
    "1. 打开 MetaTrader 5\n",
    "2. 将 `ForexRLTrader` EA 应用到 EURUSD M15 图表\n",
    "3. 先在策略测试器中回测\n",
    "4. 然后在模拟账户测试 1-2 周\n",
    "5. 充分测试后再考虑实盘\n",
    "\n",
    "### ⚠️ 重要提醒\n",
    "\n",
    "- ✅ 永远先用模拟账户测试\n",
    "- ✅ 历史表现不代表未来结果\n",
    "- ✅ 仅使用您能承受损失的资金\n",
    "- ✅ 密切监控EA运行状态\n",
    "\n",
    "---\n",
    "\n",
    "**教程完成！** 🎉"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
